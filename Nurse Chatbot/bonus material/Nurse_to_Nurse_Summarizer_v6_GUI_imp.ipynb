{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improvements**\n",
    "1. Searches Vitals PDF for normal ranges \n",
    "    1. Removed explicit vital sign information in system prompt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import threading \n",
    "import time\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Text, ForeignKey\n",
    "from sqlalchemy.orm import sessionmaker, relationship, declarative_base\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import atexit\n",
    "\n",
    "# Function to handle chatbot summarization\n",
    "from langchain_community.document_loaders import JSONLoader, PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, RecursiveJsonSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.retrievers import MergerRetriever\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat History Database setup\n",
    "DATABASE_URL = \"sqlite:///Nurse_Chat_History_2.db\"\n",
    "Base = declarative_base()\n",
    "\n",
    "class Session(Base):\n",
    "    __tablename__ = \"sessions\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    session_id = Column(String, unique=True, nullable=False)\n",
    "    messages = relationship(\"Message\", back_populates=\"session\")\n",
    "\n",
    "class Message(Base):\n",
    "    __tablename__ = \"messages\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    session_id = Column(Integer, ForeignKey(\"sessions.id\"), nullable=False)\n",
    "    role = Column(String, nullable=False)\n",
    "    content = Column(Text, nullable=False)\n",
    "    session = relationship(\"Session\", back_populates=\"messages\")\n",
    "\n",
    "# Create the database and the tables\n",
    "engine = create_engine(DATABASE_URL)\n",
    "Base.metadata.create_all(engine)\n",
    "SessionLocal = sessionmaker(bind=engine)\n",
    "\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save a single message\n",
    "def save_message(session_id: str, role: str, content: str):\n",
    "    with SessionLocal() as db:\n",
    "        try:\n",
    "            session = db.query(Session).filter(Session.session_id == session_id).first()\n",
    "            if not session:\n",
    "                session = Session(session_id=session_id)\n",
    "                db.add(session)\n",
    "                db.commit()\n",
    "                db.refresh(session)\n",
    "\n",
    "            db.add(Message(session_id=session.id, role=role, content=content))\n",
    "            db.commit()\n",
    "        except SQLAlchemyError:\n",
    "            db.rollback()\n",
    "\n",
    "\n",
    "# Function to load chat history\n",
    "def load_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    chat_history = ChatMessageHistory()\n",
    "    with SessionLocal() as db:\n",
    "        try:\n",
    "            session = db.query(Session).filter(Session.session_id == session_id).first()\n",
    "            if session:\n",
    "                for message in session.messages:\n",
    "                    chat_history.add_message({\"role\": message.role, \"content\": message.content})\n",
    "        except SQLAlchemyError:\n",
    "            pass\n",
    "\n",
    "    return chat_history\n",
    "\n",
    "\n",
    "# Modify the get_session_history function to use the database\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        # Load from the database if not in store\n",
    "        store[session_id] = load_session_history(session_id)\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# Ensure you save the chat history to the database when needed\n",
    "def save_all_sessions():\n",
    "    for session_id, chat_history in store.items():\n",
    "        for message in chat_history.messages:\n",
    "            save_message(session_id, message[\"role\"], message[\"content\"])\n",
    "\n",
    "# Register function to save sessions before exit\n",
    "atexit.register(save_all_sessions)\n",
    "\n",
    "store = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_stuff_documents_chain' from 'langchain.chains' (c:\\Users\\elfo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryVectorStore\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistory_aware_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_history_aware_retriever\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, MessagesPlaceholder\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'create_stuff_documents_chain' from 'langchain.chains' (c:\\Users\\elfo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain\\chains\\__init__.py)"
     ]
    }
   ],
   "source": [
    "def Nurse2NurseChatbotSummarize(filepath: str, session_id: str, promptQuestion: str):\n",
    "    try:\n",
    "        llm = ChatOpenAI(model='gpt-4o')\n",
    "        \n",
    "        #initilze JSONLoader to load in JSON data. jq_schemea set to '.' to load in entire JSON, text_content = False as to not parse through text\n",
    "        loader = JSONLoader(file_path=filepath, jq_schema='.', text_content=False)\n",
    "\n",
    "        #Load JSON file into memory --> docs is a list of documents  \n",
    "        docs = loader.load()\n",
    "\n",
    "        #Instantiate the recursive text splitter. Recursively break loaded document into chunks of up to 5000 characters with 200 characters of overlap. add_start_index = True to keep track of the position of each chunk\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=200, add_start_index=True)  # Increased chunk-size to 5000 from 1000\n",
    "\n",
    "        #Apply text_splitter to loaded document and break JSON into smaller documents. splits is a list of smaller chunks of text\n",
    "        splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        #generate vector embeddings for each document\n",
    "        vectorstore = InMemoryVectorStore.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "        #instantiate retriever configured to use similarity search to find documents in vector store. Used to provide context to LLM\n",
    "        retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 4})\n",
    "\n",
    "        pdf_loader = PyPDFLoader(file_path='NormalVitals.pdf')\n",
    "        pdf_docs = pdf_loader.load()\n",
    "        pdf_splits = text_splitter.split_documents(pdf_docs)\n",
    "        pdf_vectorstore = InMemoryVectorStore.from_documents(documents=pdf_splits, embedding=OpenAIEmbeddings())\n",
    "        pdf_retriever = pdf_vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 4})\n",
    "\n",
    "\n",
    "        #Above lines document processing pipeline: Load JSON, split content into smaller chunks, embed chunks, similarity-based retrieval\n",
    "\n",
    "        combined_retriever = MergerRetriever(retrievers = [retriever, pdf_retriever], retriever_weights = [0.5,0.5])\n",
    "\n",
    "        contextualize_q_system_prompt = (\n",
    "            \"Given a chat history and the latest user question \"\n",
    "            \"which might reference context in the chat history, \"\n",
    "            \"formulate a standalone question which can be understood \"\n",
    "            \"without the chat history. Do NOT answer the question, \"\n",
    "            \"just reformulate it if needed and otherwise return it as is.\"\n",
    "        )\n",
    "\n",
    "        contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", contextualize_q_system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        history_aware_retriever = create_history_aware_retriever(llm, combined_retriever, contextualize_q_prompt)\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are a nurse in the NICU at the end of your shift, preparing for patient handover. \"\n",
    "            \"Provide the incoming nurse with all pertinent information for their shift. \"\n",
    "            \"Use the 'Normal Vital Signs in Infants, Children, and Adolescents' context to determine if the vital signs are within normal ranges.\"\n",
    "            \"Use technical terms such as tachycardia, bradycardia, tachypnea, and bradypnea. \"\n",
    "            \"IF the vital sign is 141-170 and the vitalsign is measured to be 149, that therefore means within normal range.\"\n",
    "            \"Indicate if vital signs are above (tachycardia/tachypnea) or below (bradycardia/bradypnea) normal ranges. \"\n",
    "            \"Summarize the patient's status in 3 sentences, including interventions performed and the range of vital signs observed. \"\n",
    "            \"The summary should be technical and assume the colleague understands medical terminology. \"\n",
    "            \"Do not explain what is normal; focus on the context as your knowledge. \"\n",
    "            \"Avoid diagnosing. \"\n",
    "            \"\\n\\n{context}\"\n",
    "        )\n",
    "\n",
    "        qa_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "        rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "        conversational_rag_chain = RunnableWithMessageHistory(\n",
    "            rag_chain,\n",
    "            get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"answer\",\n",
    "        )\n",
    "        response = conversational_rag_chain.invoke(\n",
    "            {\"input\": promptQuestion},\n",
    "            config={\n",
    "                \"configurable\": {\"session_id\": session_id}\n",
    "            },  # constructs a key \"abc123\" in `store`.\n",
    "        )\n",
    "\n",
    "        # Save the user question and AI response to the database\n",
    "        save_message(session_id, \"human\", promptQuestion)\n",
    "        save_message(session_id, \"ai\", response['answer'])\n",
    "\n",
    "        return response['answer']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "from tkinterdnd2 import TkinterDnD, DND_FILES\n",
    "\n",
    "# Global loading flag\n",
    "loading = False\n",
    "\n",
    "# Colors and Styles\n",
    "BG_COLOR = \"#2C2C2C\"\n",
    "FG_COLOR = \"#FFFFFF\"\n",
    "BTN_COLOR = \"#4CAF50\"\n",
    "ENTRY_COLOR = \"#3E3E3E\"\n",
    "FONT = (\"Arial\", 12)\n",
    "\n",
    "# Loading Dots Animation\n",
    "def loading_dots():\n",
    "    dot_count = 0\n",
    "    while loading:\n",
    "        dot_count = (dot_count % 3) + 1\n",
    "        dots = \". \" * dot_count\n",
    "        chat_history_text.configure(state='normal')\n",
    "        chat_history_text.delete('end-1c linestart', 'end-1c')  # Remove previous dots\n",
    "        chat_history_text.insert(tk.END, dots)\n",
    "        chat_history_text.configure(state='disabled')\n",
    "        root.update_idletasks()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Run Chatbot Function\n",
    "def run_chatbot():\n",
    "    filepath = file_entry.get()\n",
    "    session_id = session_entry.get()\n",
    "    prompt = prompt_entry.get()\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        messagebox.showerror(\"Error\", \"The selected file does not exist.\")\n",
    "        return\n",
    "\n",
    "    if not session_id:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid session ID.\")\n",
    "        return\n",
    "\n",
    "    if not prompt:\n",
    "        messagebox.showerror(\"Error\", \"Please enter a prompt.\")\n",
    "        return\n",
    "\n",
    "    chat_history_text.configure(state='normal')\n",
    "    chat_history_text.insert(tk.END, f\"You: {prompt}\\nBot: \")\n",
    "    chat_history_text.configure(state='disabled')\n",
    "    root.update_idletasks()\n",
    "\n",
    "    global loading\n",
    "    loading = True\n",
    "    threading.Thread(target=loading_dots, daemon=True).start()\n",
    "\n",
    "    def generate_response():\n",
    "        global loading\n",
    "        result = Nurse2NurseChatbotSummarize(filepath, session_id, prompt)  # Placeholder for actual function\n",
    "        loading = False\n",
    "        chat_history_text.configure(state='normal')\n",
    "        chat_history_text.delete('end-1c linestart', 'end-1c')  # Remove loading dots\n",
    "        chat_history_text.insert(tk.END, f\"{result}\\n\\n\")\n",
    "        chat_history_text.configure(state='disabled')\n",
    "        prompt_entry.delete(0, tk.END)\n",
    "\n",
    "    threading.Thread(target=generate_response, daemon=True).start()\n",
    "\n",
    "# End Chat Function\n",
    "def end_chat():\n",
    "    chat_history_text.configure(state='normal')\n",
    "    chat_history_text.insert(tk.END, \"Chat session ended.\\n\\n\")\n",
    "    chat_history_text.configure(state='disabled')\n",
    "    session_entry.delete(0, tk.END)\n",
    "    prompt_entry.delete(0, tk.END)\n",
    "    file_entry.delete(0, tk.END)\n",
    "    root.after(1000, root.destroy)  # Close the GUI after 1 second\n",
    "\n",
    "# Drag-and-Drop Handler\n",
    "def on_file_drop(event):\n",
    "    file_entry.delete(0, tk.END)  # Clear existing text\n",
    "    file_entry.insert(0, event.data.strip())  # Insert the dropped file path\n",
    "\n",
    "# GUI Setup using TkinterDnD\n",
    "root = TkinterDnD.Tk()\n",
    "root.title(\"Chatbot GUI for JSON Summarization\")\n",
    "root.geometry(\"800x600\")\n",
    "root.configure(bg=BG_COLOR)\n",
    "\n",
    "# Header\n",
    "header = tk.Label(root, text=\"Chatbot Assistant\", font=(\"Arial\", 18, \"bold\"), bg=BG_COLOR, fg=FG_COLOR, pady=10)\n",
    "header.pack(fill=\"x\")\n",
    "\n",
    "# Filepath Entry Section\n",
    "frame_inputs = tk.Frame(root, bg=BG_COLOR)\n",
    "frame_inputs.pack(pady=10)\n",
    "\n",
    "file_label = tk.Label(frame_inputs, text=\"Select JSON File:\", font=FONT, bg=BG_COLOR, fg=FG_COLOR)\n",
    "file_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "\n",
    "file_entry = tk.Entry(frame_inputs, font=FONT, bg=ENTRY_COLOR, fg=FG_COLOR, bd=1, relief=\"solid\")\n",
    "file_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "# Enable drag-and-drop for file entry\n",
    "file_entry.drop_target_register(DND_FILES)\n",
    "file_entry.dnd_bind('<<Drop>>', on_file_drop)\n",
    "\n",
    "file_button = tk.Button(frame_inputs, text=\"Browse\", command=lambda: file_entry.insert(0, filedialog.askopenfilename(filetypes=[(\"JSON Files\", \"*.json\")])), bg=BTN_COLOR, fg=FG_COLOR, font=FONT, relief=\"flat\", padx=10)\n",
    "file_button.grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "# Session ID Entry\n",
    "session_label = tk.Label(frame_inputs, text=\"Enter Session ID:\", font=FONT, bg=BG_COLOR, fg=FG_COLOR)\n",
    "session_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "\n",
    "session_entry = tk.Entry(frame_inputs, font=FONT, bg=ENTRY_COLOR, fg=FG_COLOR, bd=1, relief=\"solid\")\n",
    "session_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "# Prompt Entry\n",
    "prompt_label = tk.Label(frame_inputs, text=\"Enter Prompt:\", font=FONT, bg=BG_COLOR, fg=FG_COLOR)\n",
    "prompt_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"e\")\n",
    "\n",
    "prompt_entry = tk.Entry(frame_inputs, font=FONT, bg=ENTRY_COLOR, fg=FG_COLOR, bd=1, relief=\"solid\")\n",
    "prompt_entry.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "# Chat History Display\n",
    "chat_history_text = scrolledtext.ScrolledText(root, width=80, height=20, state='disabled', wrap='word', font=FONT, bg=ENTRY_COLOR, fg=FG_COLOR, bd=1, relief=\"solid\")\n",
    "chat_history_text.pack(pady=10)\n",
    "\n",
    "# Buttons Section\n",
    "frame_buttons = tk.Frame(root, bg=BG_COLOR)\n",
    "frame_buttons.pack(pady=10)\n",
    "\n",
    "run_button = tk.Button(frame_buttons, text=\"Run Chatbot\", command=run_chatbot, bg=BTN_COLOR, fg=FG_COLOR, font=FONT, relief=\"flat\", padx=20)\n",
    "run_button.grid(row=0, column=0, padx=10)\n",
    "\n",
    "end_button = tk.Button(frame_buttons, text=\"End Chat\", command=end_chat, bg=\"#FF6347\", fg=FG_COLOR, font=FONT, relief=\"flat\", padx=20)\n",
    "end_button.grid(row=0, column=1, padx=10)\n",
    "\n",
    "# Mainloop to run the GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
